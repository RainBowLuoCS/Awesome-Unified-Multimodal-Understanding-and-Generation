
<div align="center">
   
[![LICENSE](https://img.shields.io/github/license/October2001/Awesome-KV-Cache-Compression)](https://github.com/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation/blob/main/LICENSE)
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![commit](https://img.shields.io/github/last-commit/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation?color=blue)](https://github.com/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation/commits/main)
[![PR](https://img.shields.io/badge/PRs-Welcome-red)](https://github.com/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation/pulls)
[![GitHub Repo stars](https://img.shields.io/github/stars/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation)](https://github.com/RainBowLuoCS/Awesome-Unified-Multimodal-Understanding-and-Generation)

</div>

This paper list is only used to record papers I read in the daily arxiv for personal needs. I hope this will contribute to the unified multimodal generation and understanding community. If you find I missed some important and exciting work, it would be super helpful to let me know. Thanks!

## üì¢ News
üéâ [2025-06-10] Project Beginning ü•≥

## üìú Notice

This repository is constantly updating ü§ó ...
> You can directly click on the title to jump to the corresponding PDF link location

## üîç Method

### 1Ô∏è‚É£ Image and Text

1. [**DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception.**](https://arxiv.org/abs/2405.15232) *Run Luo, Yunshui Li, Longze Chen, Wanwei He, Ting-En Lin, Ziqiang Liu, Lei Zhang, Zikai Song, Xiaobo Xia, Tongliang Liu, Min Yang, Binyuan Hui.* ICLR 2025. 


### 2Ô∏è‚É£ Audio and Text

1. [**LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis.**](https://arxiv.org/abs/2505.02625) *Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng.* ACL 2025. 


### 3Ô∏è‚É£ Image, Video and Text

1. [**VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation.**](https://arxiv.org/abs/2409.04429) *Yecheng Wu, Zhuoyang Zhang, Junyu Chen, Haotian Tang, Dacheng Li, Yunhao Fang, Ligeng Zhu, Enze Xie, Hongxu Yin, Li Yi, Song Han, Yao Lu.* ICLR 2025. 

### 4Ô∏è‚É£ Image, Audio and Text

1. [**OpenOmni: Advancing Open-Source Omnimodal Large Language Models with Progressive Multimodal Alignment and Real-time Emotional Speech Synthesis.**](https://arxiv.org/abs/2501.04561) *Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen, Jiaming Li, Lei Zhang, Yangyi Chen, Xiaobo Xia, Hamid Alinejad-Rokny, Fei Huang.* Arxiv 2024/09/15. 

### 5Ô∏è‚É£ Image, Audio, Video and Text

